{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityasingh1993/ML-DL-AI-LearnAndTry/blob/main/LLM/AXOLTL/AXOLTlFinetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYYBa4YTgYjI",
        "outputId": "ad4f4725-505e-4274-f2f7-18e3c09261ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 10 09:20:02 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCEH5nazKRMi",
        "outputId": "7ec6b821-8224-4969-c5ed-0c518c9fcfbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 16359, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16359 (delta 8), reused 12 (delta 7), pack-reused 16334 (from 1)\u001b[K\n",
            "Receiving objects: 100% (16359/16359), 5.99 MiB | 8.84 MiB/s, done.\n",
            "Resolving deltas: 100% (10663/10663), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/axolotl-ai-cloud/axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkX9BXWjKaLs",
        "outputId": "a6b6aa5f-9abd-4c9b-da62-04c4246b6f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: cd: axoltl: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd axoltl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy2nk0SPKh5f",
        "outputId": "32755f79-8fc0-417b-f6b9-7ca4a2516a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.1)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install packaging ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjFhRDhiKrUy",
        "outputId": "ad038aec-f86b-42d7-c39b-27baf05befe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/axolotl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl==0.4.1)\n",
            "  Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-cv3afn4b/fschat_19fde20d0ab546d8b09e9b4d94a0c4dd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-cv3afn4b/fschat_19fde20d0ab546d8b09e9b4d94a0c4dd\n",
            "  Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
            "  Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==23.2 (from axolotl==0.4.1)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting peft==0.13.0 (from axolotl==0.4.1)\n",
            "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers==4.45.1 (from axolotl==0.4.1)\n",
            "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (0.19.1)\n",
            "Collecting bitsandbytes==0.44.0 (from axolotl==0.4.1)\n",
            "  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (0.34.2)\n",
            "Collecting datasets==2.21.0 (from axolotl==0.4.1)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pydantic==2.6.3 (from axolotl==0.4.1)\n",
            "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from axolotl==0.4.1)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl==0.4.1)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (0.2.0)\n",
            "Collecting wandb (from axolotl==0.4.1)\n",
            "  Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (0.8.0)\n",
            "Collecting optimum==1.16.2 (from axolotl==0.4.1)\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hf_transfer (from axolotl==0.4.1)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting colorama (from axolotl==0.4.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (0.60.0)\n",
            "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (1.26.4)\n",
            "Collecting evaluate==0.4.1 (from axolotl==0.4.1)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (1.13.1)\n",
            "Collecting scikit-learn==1.4.2 (from axolotl==0.4.1)\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pynvml (from axolotl==0.4.1)\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting art (from axolotl==0.4.1)\n",
            "  Downloading art-6.3-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.2 (from axolotl==0.4.1)\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (2.17.0)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl==0.4.1)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting autoawq>=0.2.5 (from axolotl==0.4.1)\n",
            "  Downloading autoawq-0.2.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting triton>=2.3.0 (from axolotl==0.4.1)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting liger-kernel==0.3.0 (from axolotl==0.4.1)\n",
            "  Downloading liger_kernel-0.3.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting s3fs>=2024.5.0 (from axolotl==0.4.1)\n",
            "  Downloading s3fs-2024.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (2024.6.1)\n",
            "Collecting trl==0.9.6 (from axolotl==0.4.1)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl==0.4.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (1.7.10)\n",
            "Requirement already satisfied: torch==2.4.1+cu121 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.4.1) (2.4.1+cu121)\n",
            "Collecting xformers>=0.0.27 (from axolotl==0.4.1)\n",
            "  Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->axolotl==0.4.1) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->axolotl==0.4.1) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->axolotl==0.4.1) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0->axolotl==0.4.1) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0->axolotl==0.4.1) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.21.0->axolotl==0.4.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0->axolotl==0.4.1) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0->axolotl==0.4.1) (4.66.5)\n",
            "Collecting xxhash (from datasets==2.21.0->axolotl==0.4.1)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.21.0->axolotl==0.4.1)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0->axolotl==0.4.1) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0->axolotl==0.4.1) (3.10.8)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl==0.4.1)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (10.4.0)\n",
            "Collecting pydub (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.4.1) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl==0.4.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl==0.4.1) (1.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.3->axolotl==0.4.1) (0.7.0)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl==0.4.1)\n",
            "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl==0.4.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl==0.4.1) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121->axolotl==0.4.1) (3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1->axolotl==0.4.1) (2024.9.11)\n",
            "Collecting tokenizers>=0.19.1 (from axolotl==0.4.1)\n",
            "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tyro>=0.5.11 (from trl==0.9.6->axolotl==0.4.1)\n",
            "  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting flash-attn==2.6.3 (from axolotl==0.4.1)\n",
            "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed==0.14.4 (from axolotl==0.4.1)\n",
            "  Downloading deepspeed-0.14.4.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed-kernels (from axolotl==0.4.1)\n",
            "  Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
            "Collecting hjson (from deepspeed==0.14.4->axolotl==0.4.1)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.4->axolotl==0.4.1) (1.11.1.1)\n",
            "Collecting nvidia-ml-py (from deepspeed==0.14.4->axolotl==0.4.1)\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.4->axolotl==0.4.1) (9.0.0)\n",
            "INFO: pip is looking at multiple versions of autoawq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting autoawq>=0.2.5 (from axolotl==0.4.1)\n",
            "  Downloading autoawq-0.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting autoawq-kernels (from autoawq>=0.2.5->axolotl==0.4.1)\n",
            "  Downloading autoawq_kernels-0.0.8-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl==0.4.1) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl==0.4.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl==0.4.1) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl==0.4.1) (2.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl==0.4.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl==0.4.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl==0.4.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl==0.4.1) (2024.8.30)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.5.0->axolotl==0.4.1)\n",
            "  Downloading aiobotocore-2.15.2-py3-none-any.whl.metadata (23 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.5.0 (from axolotl==0.4.1)\n",
            "  Downloading s3fs-2024.6.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: cmake>=3.24 in /usr/local/lib/python3.10/dist-packages (from deepspeed-kernels->axolotl==0.4.1) (3.30.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl==0.4.1) (2.4.0)\n",
            "Collecting markdown2[all] (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading markdown2-2.5.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting nh3 (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.48)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (13.9.1)\n",
            "Collecting shortuuid (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tiktoken (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl==0.4.1) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.4.1) (3.0.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.4.1) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.4.1)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.4.1)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.4.1) (4.3.6)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.4.1)\n",
            "  Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle (from wandb->axolotl==0.4.1)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting botocore<1.35.37,>=1.35.16 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl==0.4.1)\n",
            "  Downloading botocore-1.35.36-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl==0.4.1) (1.16.0)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl==0.4.1)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0->axolotl==0.4.1) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl==0.4.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl==0.4.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl==0.4.1) (4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.21.0->axolotl==0.4.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.21.0->axolotl==0.4.1) (2024.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (2.18.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.9.6->axolotl==0.4.1) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.9.6->axolotl==0.4.1)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl==0.4.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl==0.4.1) (1.3.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (2.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2->axolotl==0.4.1) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2->axolotl==0.4.1) (1.3.1)\n",
            "Collecting wavedrom (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.21.0->axolotl==0.4.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.16.2->axolotl==0.4.1) (1.3.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl==0.4.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (1.65.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (1.24.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs>=2024.5.0->axolotl==0.4.1) (1.6.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl==0.4.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl==0.4.1) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.50.2->axolotl==0.4.1) (1.2.2)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading liger_kernel-0.3.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoawq-0.2.5-cp310-cp310-manylinux2014_x86_64.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3fs-2024.6.1-py3-none-any.whl (29 kB)\n",
            "Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading art-6.3-py3-none-any.whl (606 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.3/606.3 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.15.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.8/313.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoawq_kernels-0.0.8-cp310-cp310-manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.2/769.2 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.35.36-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed, flash-attn, fire, fschat, wavedrom\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.4-py3-none-any.whl size=1445507 sha256=1ad5581cd3f07e55ddeda372aeb044fc81f5ec41e1fb3fc15b6f8ca228545494\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/bc/a3/608e90bbb301848b78fd75d24d6d43ba3074de968fc0e397ac\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=187309225 sha256=237ef9c6157db394e1ddde4ba609a21ebb98382377a27041edc09318801a6f24\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114250 sha256=c3f1673bd8a1b1dc2ef3e4b0630f614d1a4a60bce8b6de8fd8dc5afc8ca4dce3\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "  Building wheel for fschat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fschat: filename=fschat-0.2.36-py3-none-any.whl size=272080 sha256=692e89253f6c98c2b0b98b5e731bf76c0b06c1530662225c9f56301396c407ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/dc/55/8647f928ab3e6390d35d3bb898acca851918560726ecdfc42a\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=90d1c6c39c753cb70a09a14e2051de4fb431d5de454cce8cbb7f9c6a8b1a6083\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built deepspeed flash-attn fire fschat wavedrom\n",
            "Installing collected packages: pydub, nvidia-ml-py, nh3, hjson, addict, zstandard, xxhash, websockets, triton, svgwrite, smmap, shtab, shortuuid, setproctitle, sentry-sdk, semantic-version, python-multipart, python-dotenv, pynvml, pydantic-core, packaging, orjson, markdown2, latex2mathml, jmespath, humanfriendly, hf_transfer, h11, fire, ffmpy, docker-pycreds, dill, colorama, art, aioitertools, aiofiles, wavedrom, uvicorn, tiktoken, starlette, scikit-learn, responses, pydantic, multiprocess, httpcore, gitdb, deepspeed-kernels, coloredlogs, botocore, xformers, tyro, tokenizers, httpx, gitpython, flash-attn, fastapi, deepspeed, bitsandbytes, autoawq-kernels, wandb, transformers, gradio-client, fschat, aiobotocore, s3fs, peft, liger-kernel, gradio, datasets, trl, optimum, evaluate, autoawq, axolotl\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.23.4\n",
            "    Uninstalling pydantic_core-2.23.4:\n",
            "      Successfully uninstalled pydantic_core-2.23.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Running setup.py develop for axolotl\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.15 requires pydantic>=2.7.0, but you have pydantic 2.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 aiobotocore-2.15.2 aiofiles-23.2.1 aioitertools-0.12.0 art-6.3 autoawq-0.2.5 autoawq-kernels-0.0.8 axolotl-0.4.1 bitsandbytes-0.44.0 botocore-1.35.36 colorama-0.4.6 coloredlogs-15.0.1 datasets-2.21.0 deepspeed-0.14.4 deepspeed-kernels-0.0.1.dev1698255861 dill-0.3.8 docker-pycreds-0.4.0 evaluate-0.4.1 fastapi-0.115.0 ffmpy-0.4.0 fire-0.7.0 flash-attn-2.6.3 fschat-0.2.36 gitdb-4.0.11 gitpython-3.1.43 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.8 hjson-3.1.0 httpcore-1.0.6 httpx-0.27.2 humanfriendly-10.0 jmespath-1.0.1 latex2mathml-3.77.0 liger-kernel-0.3.0 markdown2-2.5.1 multiprocess-0.70.16 nh3-0.2.18 nvidia-ml-py-12.560.30 optimum-1.16.2 orjson-3.10.7 packaging-23.2 peft-0.13.0 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pynvml-11.5.3 python-dotenv-1.0.1 python-multipart-0.0.12 responses-0.18.0 s3fs-2024.6.1 scikit-learn-1.4.2 semantic-version-2.10.0 sentry-sdk-2.16.0 setproctitle-1.3.3 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 starlette-0.38.6 svgwrite-1.4.3 tiktoken-0.8.0 tokenizers-0.20.0 transformers-4.45.1 triton-3.0.0 trl-0.9.6 tyro-0.8.11 uvicorn-0.31.1 wandb-0.18.3 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.28.post1 xxhash-3.5.0 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -e axolotl/'.[flash-attn,deepspeed]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2-Ic8Yaubwi"
      },
      "source": [
        "## Training a simple L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgYE50V_KvMW",
        "outputId": "d8aecdfc-be05-4645-cb9e-96c26411320b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-10-10 04:12:46.071851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-10 04:12:46.091742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-10 04:12:46.097793: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-10 04:12:46.111939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-10 04:12:47.256716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-10 04:12:51,434] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-10-10 04:12:51,562] [INFO] [root.spawn:61] [PID:11398] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp3l4q1g5p/test.c -o /tmp/tmp3l4q1g5p/test.o\n",
            "[2024-10-10 04:12:51,588] [INFO] [root.spawn:61] [PID:11398] x86_64-linux-gnu-gcc /tmp/tmp3l4q1g5p/test.o -laio -o /tmp/tmp3l4q1g5p/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "[2024-10-10 04:12:54,642] [DEBUG] [axolotl.normalize_config:83] [PID:11398] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "config.json: 100% 608/608 [00:00<00:00, 4.05MB/s]\n",
            "[2024-10-10 04:12:54,900] [INFO] [axolotl.normalize_config:207] [PID:11398] [RANK:0] GPU memory usage baseline: 0.000GB (+0.002GB cache, +0.352GB misc)\u001b[39m\n",
            "                                 dP            dP   dP \n",
            "                                 88            88   88 \n",
            "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                       \n",
            "                                                       \n",
            "\n",
            "****************************************\n",
            "**** Axolotl Dependency Versions *****\n",
            "  accelerate: 0.34.2         \n",
            "        peft: 0.13.0         \n",
            "transformers: 4.45.1         \n",
            "         trl: 0.9.6          \n",
            "       torch: 2.4.1+cu121    \n",
            "bitsandbytes: 0.44.0         \n",
            "****************************************\n",
            "\u001b[33m[2024-10-10 04:12:54,928] [WARNING] [axolotl.scripts.check_user_token:524] [PID:11398] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 7.73MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 17.5MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 3.70MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 6.06MB/s]\n",
            "[2024-10-10 04:12:56,329] [DEBUG] [axolotl.load_tokenizer:290] [PID:11398] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-10-10 04:12:56,329] [DEBUG] [axolotl.load_tokenizer:291] [PID:11398] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-10-10 04:12:56,329] [DEBUG] [axolotl.load_tokenizer:292] [PID:11398] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-10-10 04:12:56,330] [DEBUG] [axolotl.load_tokenizer:293] [PID:11398] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-10-10 04:12:56,330] [INFO] [axolotl.load_tokenizer:304] [PID:11398] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 04:12:56,330] [INFO] [axolotl.load_tokenized_prepared_datasets:208] [PID:11398] [RANK:0] Unable to find prepared dataset in last_run_prepared/df6848da14853e64329578d36f6a222c\u001b[39m\n",
            "[2024-10-10 04:12:56,330] [INFO] [axolotl.load_tokenized_prepared_datasets:209] [PID:11398] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-10-10 04:12:56,330] [WARNING] [axolotl.load_tokenized_prepared_datasets:211] [PID:11398] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2024-10-10 04:12:56,330] [INFO] [axolotl.load_tokenized_prepared_datasets:218] [PID:11398] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Downloading readme: 100% 404/404 [00:00<00:00, 4.46kB/s]\n",
            "Downloading data: 100% 130k/130k [00:00<00:00, 279kB/s]\n",
            "Generating train split: 100% 100/100 [00:00<00:00, 2687.50 examples/s]\n",
            "[2024-10-10 04:12:59,749] [INFO] [axolotl.get_dataset_wrapper:582] [PID:11398] [RANK:0] Loading dataset with base_type: None and prompt_style: None\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 100/100 [00:00<00:00, 208.81 examples/s]\n",
            "Dropping Long Sequences (num_proc=2): 100% 100/100 [00:00<00:00, 456.53 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=2): 100% 58/58 [00:00<00:00, 293.62 examples/s]\n",
            "[2024-10-10 04:13:00,910] [INFO] [axolotl.load_tokenized_prepared_datasets:461] [PID:11398] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/df6848da14853e64329578d36f6a222c\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 58/58 [00:00<00:00, 10929.05 examples/s]\n",
            "[2024-10-10 04:13:00,923] [DEBUG] [axolotl.calculate_total_num_steps:316] [PID:11398] [RANK:0] total_num_tokens: 48_234\u001b[39m\n",
            "[2024-10-10 04:13:00,926] [DEBUG] [axolotl.calculate_total_num_steps:333] [PID:11398] [RANK:0] `total_supervised_tokens: 45_123`\u001b[39m\n",
            "[2024-10-10 04:13:00,926] [DEBUG] [axolotl.calculate_total_num_steps:411] [PID:11398] [RANK:0] total_num_steps: 11\u001b[39m\n",
            "[2024-10-10 04:13:00,926] [DEBUG] [axolotl.train.train:67] [PID:11398] [RANK:0] loading tokenizer... TinyLlama/TinyLlama-1.1B-Chat-v1.0\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [DEBUG] [axolotl.load_tokenizer:290] [PID:11398] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [DEBUG] [axolotl.load_tokenizer:291] [PID:11398] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [DEBUG] [axolotl.load_tokenizer:292] [PID:11398] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [DEBUG] [axolotl.load_tokenizer:293] [PID:11398] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [INFO] [axolotl.load_tokenizer:304] [PID:11398] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 04:13:01,233] [DEBUG] [axolotl.train.train:99] [PID:11398] [RANK:0] loading model\u001b[39m\n",
            "model.safetensors: 100% 2.20G/2.20G [00:13<00:00, 169MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 848kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "[2024-10-10 04:13:17,782] [INFO] [axolotl.train.train:180] [PID:11398] [RANK:0] Starting trainer...\u001b[39m\n",
            "{'loss': 1.3555, 'grad_norm': 4.118975639343262, 'learning_rate': 0.0019396926207859084, 'epoch': 0.27}\n",
            " 11% 1/9 [00:22<03:02, 22.79s/it][2024-10-10 04:14:02,235] [INFO] [axolotl.callbacks.on_step_end:128] [PID:11398] [RANK:0] GPU memory usage while training: 4.445GB (+10.020GB cache, +0.386GB misc)\u001b[39m\n",
            "{'loss': 19.005, 'grad_norm': 130.2045135498047, 'learning_rate': 0.001766044443118978, 'epoch': 0.53}\n",
            "{'loss': 12.1855, 'grad_norm': 231.81790161132812, 'learning_rate': 0.0015, 'epoch': 0.8}\n",
            "{'loss': 15.2463, 'grad_norm': 198.43934631347656, 'learning_rate': 0.0011736481776669307, 'epoch': 1.07}\n",
            "{'loss': 8.9375, 'grad_norm': 41.50441360473633, 'learning_rate': 0.0008263518223330697, 'epoch': 1.33}\n",
            "{'loss': 7.4328, 'grad_norm': 11.767094612121582, 'learning_rate': 0.0005000000000000002, 'epoch': 1.6}\n",
            "{'loss': 7.1048, 'grad_norm': 7.146259307861328, 'learning_rate': 0.0002339555568810221, 'epoch': 1.87}\n",
            "{'loss': 6.9367, 'grad_norm': 9.81952953338623, 'learning_rate': 6.0307379214091684e-05, 'epoch': 2.13}\n",
            "{'loss': 6.7095, 'grad_norm': 7.963445663452148, 'learning_rate': 0.0, 'epoch': 2.4}\n",
            "{'train_runtime': 393.977, 'train_samples_per_second': 0.442, 'train_steps_per_second': 0.023, 'train_loss': 9.434836043251885, 'epoch': 2.4}\n",
            "100% 9/9 [06:33<00:00, 43.78s/it]\n",
            "[2024-10-10 04:19:52,352] [INFO] [axolotl.train.train:197] [PID:11398] [RANK:0] Training Completed!!! Saving pre-trained model to /content/drive/MyDrive/LLMTraining/TrainingShortStoryTinyLlama1B/\u001b[39m\n",
            "(LlamaForCausalLM(   (model): LlamaModel(     (embed_tokens): Embedding(32000, 2048)     (layers): ModuleList(       (0-21): 22 x LlamaDecoderLayer(         (self_attn): LlamaSdpaAttention(           (q_proj): Linear(in_features=2048, out_features=2048, bias=False)           (k_proj): Linear(in_features=2048, out_features=256, bias=False)           (v_proj): Linear(in_features=2048, out_features=256, bias=False)           (o_proj): Linear(in_features=2048, out_features=2048, bias=False)           (rotary_emb): LlamaRotaryEmbedding()         )         (mlp): LlamaMLP(           (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)           (up_proj): Linear(in_features=2048, out_features=5632, bias=False)           (down_proj): Linear(in_features=5632, out_features=2048, bias=False)           (act_fn): SiLU()         )         (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)         (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)       )     )     (norm): LlamaRMSNorm((2048,), eps=1e-05)     (rotary_emb): LlamaRotaryEmbedding()   )   (lm_head): Linear(in_features=2048, out_features=32000, bias=False) ), LlamaTokenizer(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), })\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!accelerate launch -m axolotl.cli.train config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFLbFGbmSGk",
        "outputId": "91a54c8a-291c-4e66-f244-bb006f272ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMsaj-hyK2oP",
        "outputId": "c244f7d0-8da6-456b-8918-2b261fbdfd60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "!ls drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk8zWg3OPLXZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxZMObQQnrM2",
        "outputId": "80b6e0d5-6558-447c-f1a8-8901f4f35bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-10-10 09:03:32.006371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-10 09:03:32.029050: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-10 09:03:32.036023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-10 09:03:32.052192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-10 09:03:33.225869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-10 09:03:36,276] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-10-10 09:03:36,392] [INFO] [root.spawn:61] [PID:8010] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp0k92dwwr/test.c -o /tmp/tmp0k92dwwr/test.o\n",
            "[2024-10-10 09:03:36,418] [INFO] [root.spawn:61] [PID:8010] x86_64-linux-gnu-gcc /tmp/tmp0k92dwwr/test.o -laio -o /tmp/tmp0k92dwwr/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "[2024-10-10 09:03:40,653] [DEBUG] [axolotl.normalize_config:83] [PID:8010] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "[2024-10-10 09:03:41,331] [INFO] [axolotl.normalize_config:207] [PID:8010] [RANK:0] GPU memory usage baseline: 0.000GB (+0.002GB cache, +0.352GB misc)\u001b[39m\n",
            "                                 dP            dP   dP \n",
            "                                 88            88   88 \n",
            "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                       \n",
            "                                                       \n",
            "\n",
            "****************************************\n",
            "**** Axolotl Dependency Versions *****\n",
            "  accelerate: 0.34.2         \n",
            "        peft: 0.13.0         \n",
            "transformers: 4.45.1         \n",
            "         trl: 0.9.6          \n",
            "       torch: 2.4.1+cu121    \n",
            "bitsandbytes: 0.44.0         \n",
            "****************************************\n",
            "\u001b[33m[2024-10-10 09:03:41,359] [WARNING] [axolotl.scripts.check_user_token:524] [PID:8010] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "[2024-10-10 09:03:42,332] [DEBUG] [axolotl.load_tokenizer:290] [PID:8010] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-10 09:03:42,332] [DEBUG] [axolotl.load_tokenizer:291] [PID:8010] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-10 09:03:42,332] [DEBUG] [axolotl.load_tokenizer:292] [PID:8010] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-10 09:03:42,332] [DEBUG] [axolotl.load_tokenizer:293] [PID:8010] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-10 09:03:42,332] [INFO] [axolotl.load_tokenizer:304] [PID:8010] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 09:03:42,333] [INFO] [axolotl.load_tokenized_prepared_datasets:208] [PID:8010] [RANK:0] Unable to find prepared dataset in last_run_prepared/28f0217b49b084e68fafee39fbf83b15\u001b[39m\n",
            "[2024-10-10 09:03:42,333] [INFO] [axolotl.load_tokenized_prepared_datasets:209] [PID:8010] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-10-10 09:03:42,333] [WARNING] [axolotl.load_tokenized_prepared_datasets:211] [PID:8010] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2024-10-10 09:03:42,333] [INFO] [axolotl.load_tokenized_prepared_datasets:218] [PID:8010] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Downloading readme: 100% 404/404 [00:00<00:00, 1.71kB/s]\n",
            "Downloading data: 100% 130k/130k [00:00<00:00, 247kB/s]\n",
            "Generating train split: 100% 100/100 [00:00<00:00, 3136.30 examples/s]\n",
            "[2024-10-10 09:03:49,246] [INFO] [axolotl.get_dataset_wrapper:582] [PID:8010] [RANK:0] Loading dataset with base_type: None and prompt_style: None\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 100/100 [00:02<00:00, 39.88 examples/s]\n",
            "Dropping Long Sequences (num_proc=2): 100% 100/100 [00:00<00:00, 348.98 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=2): 100% 90/90 [00:00<00:00, 280.87 examples/s]\n",
            "[2024-10-10 09:03:55,147] [INFO] [axolotl.load_tokenized_prepared_datasets:461] [PID:8010] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/28f0217b49b084e68fafee39fbf83b15\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 90/90 [00:00<00:00, 13975.32 examples/s]\n",
            "[2024-10-10 09:03:55,164] [DEBUG] [axolotl.calculate_total_num_steps:316] [PID:8010] [RANK:0] total_num_tokens: 42_522\u001b[39m\n",
            "[2024-10-10 09:03:55,167] [DEBUG] [axolotl.calculate_total_num_steps:333] [PID:8010] [RANK:0] `total_supervised_tokens: 39_997`\u001b[39m\n",
            "[2024-10-10 09:03:55,167] [DEBUG] [axolotl.calculate_total_num_steps:411] [PID:8010] [RANK:0] total_num_steps: 17\u001b[39m\n",
            "[2024-10-10 09:03:55,167] [DEBUG] [axolotl.train.train:67] [PID:8010] [RANK:0] loading tokenizer... unsloth/Meta-Llama-3.1-8B-Instruct\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [DEBUG] [axolotl.load_tokenizer:290] [PID:8010] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [DEBUG] [axolotl.load_tokenizer:291] [PID:8010] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [DEBUG] [axolotl.load_tokenizer:292] [PID:8010] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [DEBUG] [axolotl.load_tokenizer:293] [PID:8010] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [INFO] [axolotl.load_tokenizer:304] [PID:8010] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 09:03:56,115] [DEBUG] [axolotl.train.train:99] [PID:8010] [RANK:0] loading model\u001b[39m\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 76.6MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 31.5M/4.98G [00:00<00:21, 234MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 62.9M/4.98G [00:00<00:22, 215MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 105M/4.98G [00:00<00:18, 266MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 136M/4.98G [00:00<00:17, 275MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 168M/4.98G [00:00<00:17, 279MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 199M/4.98G [00:00<00:17, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 231M/4.98G [00:00<00:17, 265MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 273M/4.98G [00:01<00:16, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6% 304M/4.98G [00:01<00:15, 292MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 346M/4.98G [00:01<00:15, 303MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 377M/4.98G [00:01<00:15, 306MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 409M/4.98G [00:02<00:54, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 451M/4.98G [00:02<00:38, 116MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 482M/4.98G [00:02<00:32, 140MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 514M/4.98G [00:02<00:27, 161MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 545M/4.98G [00:02<00:23, 185MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 577M/4.98G [00:02<00:21, 208MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 608M/4.98G [00:03<00:19, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 650M/4.98G [00:03<00:17, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 692M/4.98G [00:03<00:15, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 734M/4.98G [00:03<00:15, 278MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 765M/4.98G [00:03<00:14, 282MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 797M/4.98G [00:03<00:15, 275MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 828M/4.98G [00:03<00:15, 260MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 870M/4.98G [00:03<00:14, 276MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 902M/4.98G [00:04<00:14, 273MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 933M/4.98G [00:04<00:15, 267MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 965M/4.98G [00:04<00:14, 267MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 996M/4.98G [00:04<00:14, 274MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.04G/4.98G [00:04<00:13, 285MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.07G/4.98G [00:04<00:13, 282MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.10G/4.98G [00:04<00:13, 283MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.13G/4.98G [00:04<00:13, 287MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.17G/4.98G [00:05<00:13, 292MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.21G/4.98G [00:05<00:13, 282MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.25G/4.98G [00:05<00:12, 297MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.28G/4.98G [00:05<00:13, 283MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.32G/4.98G [00:05<00:13, 274MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.35G/4.98G [00:05<00:13, 259MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.38G/4.98G [00:05<00:13, 262MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.42G/4.98G [00:05<00:14, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.45G/4.98G [00:06<00:13, 263MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.48G/4.98G [00:06<00:13, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.51G/4.98G [00:06<00:12, 277MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.54G/4.98G [00:06<00:13, 262MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.57G/4.98G [00:06<00:15, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.60G/4.98G [00:06<00:14, 233MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.64G/4.98G [00:06<00:14, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.67G/4.98G [00:07<00:14, 235MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.70G/4.98G [00:07<00:16, 197MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.73G/4.98G [00:07<00:14, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.76G/4.98G [00:07<00:15, 202MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.79G/4.98G [00:07<00:15, 211MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.82G/4.98G [00:07<00:14, 218MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.86G/4.98G [00:07<00:13, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.90G/4.98G [00:08<00:11, 264MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.93G/4.98G [00:08<00:11, 261MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.96G/4.98G [00:08<00:11, 260MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 2.00G/4.98G [00:08<00:11, 264MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.03G/4.98G [00:08<00:11, 251MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.07G/4.98G [00:08<00:13, 223MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.10G/4.98G [00:08<00:13, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.13G/4.98G [00:09<00:13, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.16G/4.98G [00:09<00:12, 219MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.19G/4.98G [00:09<00:11, 239MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.22G/4.98G [00:09<00:12, 224MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.25G/4.98G [00:09<00:12, 223MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.29G/4.98G [00:09<00:12, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.33G/4.98G [00:09<00:10, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.37G/4.98G [00:09<00:09, 281MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.40G/4.98G [00:10<00:10, 256MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.43G/4.98G [00:10<00:19, 133MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.45G/4.98G [00:10<00:21, 116MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.47G/4.98G [00:11<00:28, 88.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.50G/4.98G [00:11<00:31, 78.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.52G/4.98G [00:12<00:35, 68.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.53G/4.98G [00:14<01:44, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.56G/4.98G [00:14<01:11, 33.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.57G/4.98G [00:14<01:07, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.59G/4.98G [00:14<00:50, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.62G/4.98G [00:14<00:34, 69.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.65G/4.98G [00:15<00:24, 95.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.67G/4.98G [00:15<00:21, 109MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.71G/4.98G [00:15<00:16, 139MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.73G/4.98G [00:15<00:15, 141MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.76G/4.98G [00:15<00:13, 165MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.79G/4.98G [00:15<00:11, 196MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.82G/4.98G [00:15<00:10, 213MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.85G/4.98G [00:15<00:09, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.88G/4.98G [00:16<00:10, 203MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.92G/4.98G [00:16<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.96G/4.98G [00:16<00:08, 233MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.99G/4.98G [00:16<00:08, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.02G/4.98G [00:16<00:08, 242MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.05G/4.98G [00:16<00:07, 247MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.08G/4.98G [00:17<00:15, 121MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.12G/4.98G [00:17<00:12, 152MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.16G/4.98G [00:17<00:10, 166MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.19G/4.98G [00:17<00:09, 191MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.22G/4.98G [00:17<00:08, 198MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.25G/4.98G [00:17<00:08, 215MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.29G/4.98G [00:18<00:07, 233MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.32G/4.98G [00:18<00:07, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.36G/4.98G [00:18<00:06, 245MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.39G/4.98G [00:18<00:06, 255MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.42G/4.98G [00:18<00:06, 238MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.45G/4.98G [00:18<00:06, 249MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.48G/4.98G [00:18<00:05, 264MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.51G/4.98G [00:19<00:06, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.54G/4.98G [00:19<00:05, 245MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.58G/4.98G [00:19<00:05, 248MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.61G/4.98G [00:19<00:06, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 3.64G/4.98G [00:19<00:09, 136MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.66G/4.98G [00:20<00:10, 126MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.69G/4.98G [00:20<00:08, 152MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.72G/4.98G [00:20<00:06, 180MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.75G/4.98G [00:20<00:05, 205MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.80G/4.98G [00:20<00:04, 239MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.83G/4.98G [00:20<00:04, 254MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.86G/4.98G [00:20<00:04, 249MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.89G/4.98G [00:20<00:04, 257MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.92G/4.98G [00:21<00:04, 263MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.95G/4.98G [00:21<00:03, 265MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.98G/4.98G [00:21<00:03, 263MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.03G/4.98G [00:21<00:03, 280MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.06G/4.98G [00:21<00:03, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.09G/4.98G [00:21<00:03, 251MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.12G/4.98G [00:21<00:03, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.15G/4.98G [00:21<00:03, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.18G/4.98G [00:22<00:03, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.22G/4.98G [00:22<00:03, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.25G/4.98G [00:22<00:03, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.28G/4.98G [00:22<00:03, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.31G/4.98G [00:22<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.34G/4.98G [00:22<00:02, 232MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.37G/4.98G [00:22<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.40G/4.98G [00:23<00:02, 232MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.44G/4.98G [00:23<00:02, 223MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.47G/4.98G [00:23<00:02, 222MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.50G/4.98G [00:23<00:02, 221MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.53G/4.98G [00:23<00:01, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.56G/4.98G [00:23<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.59G/4.98G [00:23<00:01, 232MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.62G/4.98G [00:24<00:01, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.66G/4.98G [00:24<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.69G/4.98G [00:24<00:01, 224MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.72G/4.98G [00:24<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.76G/4.98G [00:24<00:00, 258MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.79G/4.98G [00:24<00:00, 261MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.82G/4.98G [00:24<00:00, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.85G/4.98G [00:25<00:00, 224MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.89G/4.98G [00:25<00:00, 122MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.92G/4.98G [00:25<00:00, 124MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.94G/4.98G [00:26<00:00, 100MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:26<00:00, 188MB/s]\n",
            "Downloading shards:  25% 1/4 [00:26<01:20, 26.80s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 31.5M/5.00G [00:00<00:19, 256MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 73.4M/5.00G [00:00<00:15, 313MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 115M/5.00G [00:00<00:15, 321MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 157M/5.00G [00:00<00:15, 315MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 199M/5.00G [00:00<00:14, 326MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 241M/5.00G [00:00<00:16, 297MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 273M/5.00G [00:00<00:15, 301MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 304M/5.00G [00:00<00:15, 303MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 346M/5.00G [00:01<00:15, 299MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 388M/5.00G [00:01<00:15, 306MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 419M/5.00G [00:01<00:15, 294MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 451M/5.00G [00:01<00:16, 273MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 482M/5.00G [00:01<00:17, 265MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 514M/5.00G [00:01<00:17, 255MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 545M/5.00G [00:02<00:25, 176MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 566M/5.00G [00:02<00:24, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 598M/5.00G [00:02<00:22, 197MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 629M/5.00G [00:02<00:20, 209MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 671M/5.00G [00:02<00:18, 234MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 703M/5.00G [00:02<00:17, 241MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 734M/5.00G [00:02<00:17, 242MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 765M/5.00G [00:02<00:16, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 797M/5.00G [00:03<00:16, 255MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 828M/5.00G [00:03<00:16, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 860M/5.00G [00:03<00:16, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 891M/5.00G [00:03<00:15, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 923M/5.00G [00:03<00:17, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 954M/5.00G [00:03<00:16, 243MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 986M/5.00G [00:03<00:17, 233MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 1.02G/5.00G [00:04<00:17, 231MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.05G/5.00G [00:04<00:15, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.08G/5.00G [00:04<00:14, 265MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.11G/5.00G [00:04<00:15, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.15G/5.00G [00:04<00:14, 269MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.18G/5.00G [00:04<00:16, 235MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.22G/5.00G [00:04<00:16, 225MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.25G/5.00G [00:04<00:16, 233MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.28G/5.00G [00:05<00:24, 151MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.31G/5.00G [00:05<00:22, 167MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.34G/5.00G [00:05<00:19, 185MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.37G/5.00G [00:05<00:18, 197MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.41G/5.00G [00:05<00:17, 209MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.44G/5.00G [00:06<00:16, 216MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.47G/5.00G [00:06<00:15, 232MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.50G/5.00G [00:06<00:15, 222MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.53G/5.00G [00:06<00:15, 220MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.56G/5.00G [00:06<00:15, 215MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.59G/5.00G [00:06<00:16, 208MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.63G/5.00G [00:06<00:15, 215MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.66G/5.00G [00:07<00:14, 227MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.69G/5.00G [00:07<00:14, 232MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.72G/5.00G [00:07<00:13, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.76G/5.00G [00:07<00:11, 277MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.80G/5.00G [00:07<00:10, 307MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.84G/5.00G [00:07<00:11, 284MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.88G/5.00G [00:07<00:10, 299MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.91G/5.00G [00:07<00:10, 292MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.95G/5.00G [00:07<00:10, 305MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.98G/5.00G [00:08<00:10, 296MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 2.01G/5.00G [00:08<00:11, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 2.06G/5.00G [00:08<00:10, 268MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.09G/5.00G [00:08<00:11, 244MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.12G/5.00G [00:08<00:11, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.15G/5.00G [00:08<00:11, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.18G/5.00G [00:08<00:10, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.21G/5.00G [00:09<00:10, 266MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.24G/5.00G [00:09<00:11, 246MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.28G/5.00G [00:09<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.31G/5.00G [00:09<00:10, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.34G/5.00G [00:09<00:11, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.37G/5.00G [00:09<00:11, 220MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.41G/5.00G [00:09<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.44G/5.00G [00:10<00:11, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.47G/5.00G [00:10<00:11, 219MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.51G/5.00G [00:10<00:15, 156MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.54G/5.00G [00:10<00:13, 179MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.57G/5.00G [00:10<00:13, 185MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.60G/5.00G [00:10<00:11, 209MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.63G/5.00G [00:11<00:11, 202MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.66G/5.00G [00:11<00:18, 126MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.68G/5.00G [00:12<00:25, 90.6MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.71G/5.00G [00:12<00:31, 73.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.73G/5.00G [00:12<00:29, 76.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.75G/5.00G [00:12<00:24, 91.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.77G/5.00G [00:13<00:27, 81.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.81G/5.00G [00:13<00:21, 104MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.83G/5.00G [00:13<00:24, 87.9MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.84G/5.00G [00:13<00:26, 81.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.85G/5.00G [00:14<00:25, 84.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.86G/5.00G [00:14<00:24, 86.8MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.88G/5.00G [00:14<00:21, 97.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.90G/5.00G [00:14<00:18, 116MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.93G/5.00G [00:14<00:22, 92.5MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.95G/5.00G [00:14<00:21, 95.3MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.97G/5.00G [00:15<00:21, 96.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 3.00G/5.00G [00:15<00:15, 132MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.04G/5.00G [00:15<00:10, 181MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:15<00:09, 206MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.11G/5.00G [00:15<00:07, 242MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.16G/5.00G [00:15<00:06, 264MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.19G/5.00G [00:15<00:06, 262MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.23G/5.00G [00:16<00:06, 283MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.27G/5.00G [00:16<00:05, 290MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.30G/5.00G [00:16<00:06, 281MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.34G/5.00G [00:16<00:05, 300MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.38G/5.00G [00:16<00:05, 291MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.42G/5.00G [00:16<00:05, 289MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.45G/5.00G [00:16<00:05, 293MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.49G/5.00G [00:16<00:05, 288MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.52G/5.00G [00:17<00:05, 291MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.55G/5.00G [00:17<00:05, 279MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.59G/5.00G [00:17<00:05, 264MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.62G/5.00G [00:17<00:05, 248MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.65G/5.00G [00:17<00:05, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.69G/5.00G [00:19<00:27, 48.0MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.74G/5.00G [00:19<00:17, 73.2MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.79G/5.00G [00:19<00:12, 94.7MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.82G/5.00G [00:20<00:10, 108MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.85G/5.00G [00:20<00:08, 130MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.89G/5.00G [00:20<00:06, 163MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.92G/5.00G [00:20<00:06, 176MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.95G/5.00G [00:20<00:05, 194MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80% 4.00G/5.00G [00:20<00:04, 214MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.03G/5.00G [00:20<00:04, 226MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.06G/5.00G [00:21<00:04, 231MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.09G/5.00G [00:21<00:03, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.12G/5.00G [00:21<00:03, 224MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.15G/5.00G [00:21<00:03, 241MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.18G/5.00G [00:21<00:03, 256MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.22G/5.00G [00:21<00:03, 230MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [00:21<00:02, 256MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.29G/5.00G [00:21<00:02, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.32G/5.00G [00:22<00:02, 244MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.35G/5.00G [00:22<00:02, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.38G/5.00G [00:22<00:02, 244MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.41G/5.00G [00:22<00:02, 212MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.45G/5.00G [00:22<00:02, 190MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.47G/5.00G [00:22<00:02, 178MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.49G/5.00G [00:23<00:03, 164MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.51G/5.00G [00:23<00:03, 161MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.54G/5.00G [00:23<00:02, 170MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:23<00:02, 191MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.60G/5.00G [00:23<00:01, 215MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.63G/5.00G [00:23<00:01, 226MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.67G/5.00G [00:23<00:01, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.70G/5.00G [00:23<00:01, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.73G/5.00G [00:24<00:01, 252MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.76G/5.00G [00:24<00:00, 262MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.79G/5.00G [00:24<00:00, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.82G/5.00G [00:24<00:00, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.85G/5.00G [00:24<00:00, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.89G/5.00G [00:24<00:00, 248MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.92G/5.00G [00:24<00:00, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99% 4.95G/5.00G [00:24<00:00, 230MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:25<00:00, 199MB/s]\n",
            "Downloading shards:  50% 2/4 [00:52<00:52, 26.13s/it]\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 31.5M/4.92G [00:00<00:16, 293MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 73.4M/4.92G [00:00<00:15, 320MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 115M/4.92G [00:00<00:19, 253MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 147M/4.92G [00:00<00:30, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 168M/4.92G [00:00<00:28, 166MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 199M/4.92G [00:01<00:25, 183MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 231M/4.92G [00:01<00:24, 190MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 262M/4.92G [00:01<00:22, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 294M/4.92G [00:01<00:21, 214MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 325M/4.92G [00:01<00:21, 210MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 357M/4.92G [00:01<00:20, 218MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 388M/4.92G [00:01<00:20, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 419M/4.92G [00:01<00:19, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 451M/4.92G [00:02<00:19, 234MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 482M/4.92G [00:02<00:19, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 514M/4.92G [00:02<00:18, 241MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 545M/4.92G [00:02<00:18, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 577M/4.92G [00:02<00:17, 246MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 608M/4.92G [00:02<00:17, 242MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 640M/4.92G [00:02<00:17, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 671M/4.92G [00:03<00:16, 253MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 713M/4.92G [00:03<00:15, 276MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 744M/4.92G [00:03<00:15, 277MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 776M/4.92G [00:03<00:14, 276MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 807M/4.92G [00:03<00:14, 276MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 849M/4.92G [00:03<00:13, 296MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 881M/4.92G [00:03<00:13, 297MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 923M/4.92G [00:03<00:12, 308MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 954M/4.92G [00:03<00:13, 298MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 996M/4.92G [00:04<00:12, 322MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 1.04G/4.92G [00:04<00:12, 319MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.08G/4.92G [00:04<00:13, 294MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.11G/4.92G [00:04<00:12, 297MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.14G/4.92G [00:04<00:13, 289MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.18G/4.92G [00:04<00:12, 297MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.22G/4.92G [00:04<00:12, 288MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.26G/4.92G [00:04<00:12, 291MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.29G/4.92G [00:05<00:13, 274MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.32G/4.92G [00:05<00:13, 267MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.35G/4.92G [00:05<00:14, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.39G/4.92G [00:05<00:13, 268MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.43G/4.92G [00:05<00:12, 274MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.46G/4.92G [00:05<00:14, 242MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.50G/4.92G [00:05<00:12, 266MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.53G/4.92G [00:06<00:13, 254MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.56G/4.92G [00:06<00:14, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.59G/4.92G [00:06<00:13, 254MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.63G/4.92G [00:08<01:13, 45.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.68G/4.92G [00:08<00:45, 71.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.72G/4.92G [00:08<00:33, 95.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.75G/4.92G [00:08<00:27, 114MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.78G/4.92G [00:08<00:23, 135MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.81G/4.92G [00:11<01:36, 32.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.84G/4.92G [00:12<01:37, 31.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.87G/4.92G [00:12<01:10, 43.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.90G/4.92G [00:12<00:51, 58.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.93G/4.92G [00:13<00:43, 68.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.95G/4.92G [00:13<00:59, 49.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.97G/4.92G [00:14<00:55, 53.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 2.00G/4.92G [00:14<00:40, 71.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 2.03G/4.92G [00:14<00:30, 93.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.07G/4.92G [00:14<00:24, 118MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 2.10G/4.92G [00:14<00:19, 144MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 2.13G/4.92G [00:14<00:16, 166MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.16G/4.92G [00:14<00:15, 174MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.19G/4.92G [00:15<00:14, 185MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.22G/4.92G [00:15<00:15, 179MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.24G/4.92G [00:15<00:15, 175MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.28G/4.92G [00:15<00:13, 194MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.30G/4.92G [00:15<00:13, 195MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.32G/4.92G [00:15<00:13, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.34G/4.92G [00:15<00:13, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.36G/4.92G [00:15<00:12, 198MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.39G/4.92G [00:16<00:12, 204MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.42G/4.92G [00:16<00:11, 211MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 2.45G/4.92G [00:16<00:11, 209MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.49G/4.92G [00:16<00:11, 214MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.52G/4.92G [00:16<00:10, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.55G/4.92G [00:16<00:11, 214MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.58G/4.92G [00:17<00:14, 166MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.62G/4.92G [00:17<00:12, 190MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.65G/4.92G [00:17<00:11, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.68G/4.92G [00:17<00:10, 215MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.72G/4.92G [00:17<00:10, 219MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.75G/4.92G [00:17<00:09, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.79G/4.92G [00:17<00:08, 263MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.82G/4.92G [00:18<00:08, 253MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.85G/4.92G [00:18<00:08, 254MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.88G/4.92G [00:18<00:10, 201MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.92G/4.92G [00:18<00:09, 220MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.95G/4.92G [00:18<00:08, 232MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.98G/4.92G [00:18<00:08, 231MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 3.01G/4.92G [00:18<00:08, 228MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.04G/4.92G [00:19<00:08, 209MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.07G/4.92G [00:19<00:08, 226MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.10G/4.92G [00:19<00:07, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 3.14G/4.92G [00:19<00:07, 247MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.18G/4.92G [00:19<00:06, 261MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.21G/4.92G [00:22<00:52, 32.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 3.24G/4.92G [00:22<00:39, 41.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.27G/4.92G [00:23<00:29, 55.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.30G/4.92G [00:23<00:22, 72.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.33G/4.92G [00:23<00:18, 87.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.37G/4.92G [00:23<00:14, 109MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 3.40G/4.92G [00:24<00:18, 82.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.42G/4.92G [00:24<00:17, 86.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.44G/4.92G [00:24<00:17, 85.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.47G/4.92G [00:24<00:14, 103MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.49G/4.92G [00:24<00:12, 110MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.51G/4.92G [00:24<00:11, 122MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.53G/4.92G [00:25<00:14, 96.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.55G/4.92G [00:25<00:14, 92.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.58G/4.92G [00:25<00:14, 95.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.60G/4.92G [00:25<00:12, 103MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.62G/4.92G [00:26<00:13, 99.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.64G/4.92G [00:26<00:11, 114MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.67G/4.92G [00:26<00:08, 151MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.70G/4.92G [00:26<00:06, 175MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.74G/4.92G [00:26<00:05, 204MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.77G/4.92G [00:26<00:06, 189MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.80G/4.92G [00:26<00:05, 191MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.83G/4.92G [00:27<00:05, 198MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.85G/4.92G [00:27<00:05, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.87G/4.92G [00:27<00:05, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.90G/4.92G [00:27<00:04, 210MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.93G/4.92G [00:27<00:04, 215MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.96G/4.92G [00:27<00:04, 221MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 4.00G/4.92G [00:27<00:04, 223MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.03G/4.92G [00:28<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.06G/4.92G [00:28<00:03, 232MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.09G/4.92G [00:28<00:03, 238MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.12G/4.92G [00:28<00:03, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.15G/4.92G [00:28<00:03, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.18G/4.92G [00:28<00:03, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.22G/4.92G [00:28<00:03, 226MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.25G/4.92G [00:28<00:02, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.29G/4.92G [00:29<00:02, 246MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 4.32G/4.92G [00:29<00:02, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.35G/4.92G [00:29<00:02, 235MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.38G/4.92G [00:29<00:02, 240MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.41G/4.92G [00:30<00:07, 65.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.45G/4.92G [00:30<00:05, 83.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.47G/4.92G [00:31<00:04, 95.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:31<00:03, 110MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.51G/4.92G [00:31<00:03, 124MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.54G/4.92G [00:31<00:02, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.57G/4.92G [00:31<00:02, 169MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.60G/4.92G [00:31<00:01, 197MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.63G/4.92G [00:31<00:01, 222MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 4.67G/4.92G [00:31<00:01, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.70G/4.92G [00:31<00:00, 252MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.73G/4.92G [00:32<00:00, 262MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 4.77G/4.92G [00:32<00:00, 277MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.80G/4.92G [00:32<00:00, 273MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.83G/4.92G [00:32<00:00, 277MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.87G/4.92G [00:32<00:00, 276MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:32<00:00, 150MB/s]\n",
            "Downloading shards:  75% 3/4 [01:25<00:29, 29.39s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3% 31.5M/1.17G [00:00<00:05, 227MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   5% 62.9M/1.17G [00:00<00:04, 236MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   8% 94.4M/1.17G [00:00<00:04, 248MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  11% 126M/1.17G [00:00<00:04, 251MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 157M/1.17G [00:00<00:04, 245MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17% 199M/1.17G [00:00<00:03, 262MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  20% 231M/1.17G [00:00<00:03, 258MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  22% 262M/1.17G [00:01<00:03, 263MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  25% 294M/1.17G [00:01<00:03, 269MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  29% 336M/1.17G [00:01<00:02, 293MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 377M/1.17G [00:01<00:02, 303MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  36% 419M/1.17G [00:01<00:02, 327MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  39% 461M/1.17G [00:01<00:02, 323MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  43% 503M/1.17G [00:01<00:02, 316MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  47% 545M/1.17G [00:01<00:02, 291MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  49% 577M/1.17G [00:02<00:02, 294MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  53% 619M/1.17G [00:02<00:01, 301MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  56% 650M/1.17G [00:02<00:01, 300MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  59% 692M/1.17G [00:02<00:01, 313MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  63% 734M/1.17G [00:02<00:01, 312MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66% 776M/1.17G [00:02<00:01, 316MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70% 818M/1.17G [00:02<00:01, 288MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 849M/1.17G [00:02<00:01, 284MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  76% 891M/1.17G [00:03<00:00, 291MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  79% 923M/1.17G [00:03<00:00, 286MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82% 954M/1.17G [00:03<00:00, 262MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  84% 986M/1.17G [00:03<00:00, 264MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  87% 1.02G/1.17G [00:03<00:00, 245MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  91% 1.06G/1.17G [00:03<00:00, 261MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  93% 1.09G/1.17G [00:03<00:00, 226MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  96% 1.12G/1.17G [00:04<00:00, 234MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:04<00:00, 275MB/s]\n",
            "Downloading shards: 100% 4/4 [01:30<00:00, 22.61s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:02<00:00,  1.72it/s]\n",
            "generation_config.json: 100% 234/234 [00:00<00:00, 1.58MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 72, in <module>\n",
            "    fire.Fire(do_cli)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 39, in do_cli\n",
            "    return do_train(parsed_cfg, parsed_cli_args)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 67, in do_train\n",
            "    return train(cfg=cfg, cli_args=cli_args, dataset_meta=dataset_meta)\n",
            "  File \"/content/axolotl/src/axolotl/train.py\", line 124, in train\n",
            "    trainer = setup_trainer(\n",
            "  File \"/content/axolotl/src/axolotl/utils/trainer.py\", line 498, in setup_trainer\n",
            "    return trainer_builder.build(total_num_steps)\n",
            "  File \"/content/axolotl/src/axolotl/core/trainer_builder.py\", line 1625, in build\n",
            "    trainer = trainer_cls(\n",
            "  File \"/content/axolotl/src/axolotl/core/trainer_builder.py\", line 409, in __init__\n",
            "    super().__init__(*_args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 554, in __init__\n",
            "    self._move_model_to_device(model, args.device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 802, in _move_model_to_device\n",
            "    model = model.to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 2958, in to\n",
            "    return super().to(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1174, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 2 more times]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
            "    return t.to(\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 85.06 MiB is free. Process 93853 has 14.66 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 125.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1174, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 769, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.train', '/content/drive/MyDrive/LLMTraining/LLama8Btraining/config.yaml']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch -m axolotl.cli.train /content/drive/MyDrive/LLMTraining/LLama8Btraining/config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inU8pnFHnua2",
        "outputId": "c34181d3-6832-48a4-8517-6a296bcba847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?1l\u001b>"
          ]
        }
      ],
      "source": [
        "!watch -n -1 nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KJRWF-BqcaE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxQ9k18jslEp",
        "outputId": "858fa6f9-ca89-4641-bfa9-66faab9865b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-10-10 09:23:19.434436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-10 09:23:19.454040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-10 09:23:19.460894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-10 09:23:19.474802: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-10 09:23:20.597256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-10 09:23:24,426] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "df: /root/.triton/autotune: No such file or directory\n",
            "[2024-10-10 09:23:24,512] [INFO] [root.spawn:61] [PID:3385] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp2b6tlx34/test.c -o /tmp/tmp2b6tlx34/test.o\n",
            "[2024-10-10 09:23:24,556] [INFO] [root.spawn:61] [PID:3385] x86_64-linux-gnu-gcc /tmp/tmp2b6tlx34/test.o -laio -o /tmp/tmp2b6tlx34/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\u001b[33m[2024-10-10 09:23:30,152] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1128] [PID:3385] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "[2024-10-10 09:23:30,152] [DEBUG] [axolotl.normalize_config:83] [PID:3385] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "config.json: 100% 969/969 [00:00<00:00, 6.16MB/s]\n",
            "[2024-10-10 09:23:30,658] [INFO] [axolotl.normalize_config:207] [PID:3385] [RANK:0] GPU memory usage baseline: 0.000GB (+0.002GB cache, +0.352GB misc)\u001b[39m\n",
            "                                 dP            dP   dP \n",
            "                                 88            88   88 \n",
            "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                       \n",
            "                                                       \n",
            "\n",
            "****************************************\n",
            "**** Axolotl Dependency Versions *****\n",
            "  accelerate: 0.34.2         \n",
            "        peft: 0.13.0         \n",
            "transformers: 4.45.1         \n",
            "         trl: 0.9.6          \n",
            "       torch: 2.4.1+cu121    \n",
            "bitsandbytes: 0.44.0         \n",
            "****************************************\n",
            "\u001b[33m[2024-10-10 09:23:30,685] [WARNING] [axolotl.scripts.check_user_token:524] [PID:3385] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "tokenizer_config.json: 100% 55.4k/55.4k [00:00<00:00, 263kB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 19.9MB/s]\n",
            "special_tokens_map.json: 100% 340/340 [00:00<00:00, 2.45MB/s]\n",
            "[2024-10-10 09:23:34,023] [DEBUG] [axolotl.load_tokenizer:290] [PID:3385] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-10 09:23:34,023] [DEBUG] [axolotl.load_tokenizer:291] [PID:3385] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-10 09:23:34,023] [DEBUG] [axolotl.load_tokenizer:292] [PID:3385] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-10 09:23:34,023] [DEBUG] [axolotl.load_tokenizer:293] [PID:3385] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-10 09:23:34,023] [INFO] [axolotl.load_tokenizer:304] [PID:3385] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 09:23:34,024] [INFO] [axolotl.load_tokenized_prepared_datasets:208] [PID:3385] [RANK:0] Unable to find prepared dataset in last_run_prepared/28f0217b49b084e68fafee39fbf83b15\u001b[39m\n",
            "[2024-10-10 09:23:34,024] [INFO] [axolotl.load_tokenized_prepared_datasets:209] [PID:3385] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-10-10 09:23:34,024] [WARNING] [axolotl.load_tokenized_prepared_datasets:211] [PID:3385] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2024-10-10 09:23:34,024] [INFO] [axolotl.load_tokenized_prepared_datasets:218] [PID:3385] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Downloading readme: 100% 404/404 [00:00<00:00, 1.72kB/s]\n",
            "Downloading data: 100% 130k/130k [00:00<00:00, 495kB/s]\n",
            "Generating train split: 100% 100/100 [00:00<00:00, 2953.65 examples/s]\n",
            "[2024-10-10 09:23:40,706] [INFO] [axolotl.get_dataset_wrapper:582] [PID:3385] [RANK:0] Loading dataset with base_type: None and prompt_style: None\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 100/100 [00:03<00:00, 33.11 examples/s]\n",
            "Dropping Long Sequences (num_proc=2): 100% 100/100 [00:00<00:00, 326.84 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=2): 100% 90/90 [00:00<00:00, 371.38 examples/s]\n",
            "[2024-10-10 09:23:47,339] [INFO] [axolotl.load_tokenized_prepared_datasets:461] [PID:3385] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/28f0217b49b084e68fafee39fbf83b15\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 90/90 [00:00<00:00, 9583.57 examples/s]\n",
            "[2024-10-10 09:23:47,361] [DEBUG] [axolotl.calculate_total_num_steps:316] [PID:3385] [RANK:0] total_num_tokens: 42_522\u001b[39m\n",
            "[2024-10-10 09:23:47,364] [DEBUG] [axolotl.calculate_total_num_steps:333] [PID:3385] [RANK:0] `total_supervised_tokens: 39_997`\u001b[39m\n",
            "[2024-10-10 09:23:47,364] [DEBUG] [axolotl.calculate_total_num_steps:411] [PID:3385] [RANK:0] total_num_steps: 68\u001b[39m\n",
            "[2024-10-10 09:23:47,364] [DEBUG] [axolotl.train.train:67] [PID:3385] [RANK:0] loading tokenizer... unsloth/Meta-Llama-3.1-8B-Instruct\u001b[39m\n",
            "[2024-10-10 09:23:48,600] [DEBUG] [axolotl.load_tokenizer:290] [PID:3385] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-10 09:23:48,601] [DEBUG] [axolotl.load_tokenizer:291] [PID:3385] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-10 09:23:48,601] [DEBUG] [axolotl.load_tokenizer:292] [PID:3385] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-10 09:23:48,601] [DEBUG] [axolotl.load_tokenizer:293] [PID:3385] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-10 09:23:48,601] [INFO] [axolotl.load_tokenizer:304] [PID:3385] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-10-10 09:23:48,601] [DEBUG] [axolotl.train.train:99] [PID:3385] [RANK:0] loading model and peft_config...\u001b[39m\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 59.4MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 41.9M/4.98G [00:00<00:12, 393MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 83.9M/4.98G [00:00<00:12, 380MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 126M/4.98G [00:00<00:13, 363MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 168M/4.98G [00:00<00:14, 339MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 210M/4.98G [00:00<00:14, 334MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 252M/4.98G [00:00<00:14, 324MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6% 294M/4.98G [00:00<00:15, 294MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 325M/4.98G [00:01<00:16, 276MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 357M/4.98G [00:01<00:16, 281MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 388M/4.98G [00:01<00:18, 242MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 419M/4.98G [00:01<00:20, 227MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 461M/4.98G [00:01<00:17, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 503M/4.98G [00:02<00:53, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 535M/4.98G [00:02<00:43, 103MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 587M/4.98G [00:03<00:30, 146MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 619M/4.98G [00:03<00:26, 166MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 650M/4.98G [00:03<00:24, 178MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 692M/4.98G [00:03<00:20, 211MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 734M/4.98G [00:03<00:17, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 765M/4.98G [00:06<01:51, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 797M/4.98G [00:06<01:24, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 839M/4.98G [00:06<00:59, 69.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 870M/4.98G [00:06<00:47, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 902M/4.98G [00:06<00:39, 103MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 933M/4.98G [00:07<00:34, 118MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 965M/4.98G [00:07<00:29, 136MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 996M/4.98G [00:07<00:25, 157MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.04G/4.98G [00:07<00:20, 188MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.07G/4.98G [00:07<00:19, 202MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.10G/4.98G [00:07<00:17, 217MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.13G/4.98G [00:07<00:17, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.17G/4.98G [00:07<00:15, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.21G/4.98G [00:08<00:15, 247MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.24G/4.98G [00:08<00:15, 240MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.27G/4.98G [00:08<00:15, 244MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.30G/4.98G [00:08<00:15, 235MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.33G/4.98G [00:08<00:15, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.36G/4.98G [00:08<00:14, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.39G/4.98G [00:08<00:14, 248MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.43G/4.98G [00:08<00:13, 262MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.46G/4.98G [00:09<00:13, 257MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.49G/4.98G [00:09<00:12, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.52G/4.98G [00:09<00:13, 247MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.55G/4.98G [00:09<00:15, 227MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.58G/4.98G [00:09<00:14, 229MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.61G/4.98G [00:09<00:14, 235MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.65G/4.98G [00:09<00:13, 246MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.68G/4.98G [00:10<00:12, 261MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.71G/4.98G [00:10<00:18, 175MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.74G/4.98G [00:10<00:16, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.79G/4.98G [00:10<00:12, 258MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.82G/4.98G [00:10<00:11, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.86G/4.98G [00:10<00:12, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:10<00:12, 238MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.92G/4.98G [00:11<00:13, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.95G/4.98G [00:11<00:12, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.99G/4.98G [00:11<00:11, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.02G/4.98G [00:11<00:10, 270MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.07G/4.98G [00:11<00:10, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.10G/4.98G [00:11<00:11, 248MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.13G/4.98G [00:11<00:11, 244MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.16G/4.98G [00:12<00:11, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.19G/4.98G [00:12<00:11, 246MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.23G/4.98G [00:12<00:10, 270MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.26G/4.98G [00:12<00:10, 265MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.30G/4.98G [00:12<00:10, 255MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.34G/4.98G [00:12<00:09, 278MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.38G/4.98G [00:12<00:09, 280MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.41G/4.98G [00:12<00:09, 276MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.44G/4.98G [00:13<00:09, 277MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.47G/4.98G [00:13<00:09, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.52G/4.98G [00:13<00:09, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.56G/4.98G [00:13<00:08, 297MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.59G/4.98G [00:13<00:09, 265MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.62G/4.98G [00:13<00:11, 201MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.65G/4.98G [00:14<00:15, 150MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.68G/4.98G [00:14<00:13, 169MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.73G/4.98G [00:14<00:10, 206MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.76G/4.98G [00:14<00:11, 196MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.79G/4.98G [00:14<00:10, 212MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.83G/4.98G [00:14<00:08, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.87G/4.98G [00:15<00:07, 265MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.92G/4.98G [00:15<00:07, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.96G/4.98G [00:15<00:06, 301MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 3.01G/4.98G [00:15<00:05, 333MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.05G/4.98G [00:15<00:08, 241MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.08G/4.98G [00:16<00:11, 160MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.11G/4.98G [00:16<00:10, 175MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.16G/4.98G [00:16<00:08, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.19G/4.98G [00:16<00:07, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.23G/4.98G [00:16<00:06, 255MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.26G/4.98G [00:16<00:06, 256MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.30G/4.98G [00:16<00:05, 282MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.33G/4.98G [00:16<00:05, 285MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.38G/4.98G [00:17<00:05, 291MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.42G/4.98G [00:17<00:04, 322MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.46G/4.98G [00:17<00:05, 292MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.49G/4.98G [00:17<00:05, 252MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.54G/4.98G [00:17<00:05, 280MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.58G/4.98G [00:17<00:05, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 3.63G/4.98G [00:17<00:04, 304MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.66G/4.98G [00:18<00:04, 288MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.69G/4.98G [00:18<00:05, 216MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.72G/4.98G [00:18<00:05, 231MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.75G/4.98G [00:18<00:05, 230MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.79G/4.98G [00:18<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.82G/4.98G [00:18<00:04, 261MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.85G/4.98G [00:18<00:04, 275MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.89G/4.98G [00:18<00:03, 299MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.93G/4.98G [00:19<00:03, 309MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.97G/4.98G [00:19<00:03, 299MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 4.01G/4.98G [00:19<00:03, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.04G/4.98G [00:19<00:03, 246MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.07G/4.98G [00:19<00:05, 169MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.10G/4.98G [00:20<00:04, 186MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.14G/4.98G [00:20<00:03, 225MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.17G/4.98G [00:20<00:03, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.20G/4.98G [00:20<00:02, 259MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.25G/4.98G [00:20<00:02, 295MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.29G/4.98G [00:20<00:02, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.32G/4.98G [00:20<00:02, 255MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.35G/4.98G [00:20<00:02, 257MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.38G/4.98G [00:20<00:02, 268MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.41G/4.98G [00:21<00:02, 245MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.45G/4.98G [00:21<00:02, 249MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.48G/4.98G [00:21<00:02, 249MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.51G/4.98G [00:21<00:01, 254MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.54G/4.98G [00:21<00:01, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.57G/4.98G [00:21<00:01, 246MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.60G/4.98G [00:21<00:01, 258MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.63G/4.98G [00:21<00:01, 256MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.67G/4.98G [00:22<00:01, 263MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.71G/4.98G [00:22<00:00, 275MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.74G/4.98G [00:22<00:00, 263MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.77G/4.98G [00:22<00:00, 227MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.80G/4.98G [00:22<00:00, 239MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.83G/4.98G [00:22<00:00, 242MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.87G/4.98G [00:22<00:00, 242MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.90G/4.98G [00:23<00:00, 220MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.93G/4.98G [00:23<00:00, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:23<00:00, 212MB/s]\n",
            "Downloading shards:  25% 1/4 [00:23<01:11, 23.98s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 41.9M/5.00G [00:00<00:16, 295MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 73.4M/5.00G [00:00<00:16, 299MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 105M/5.00G [00:00<00:18, 266MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 136M/5.00G [00:00<00:18, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 168M/5.00G [00:00<00:17, 272MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 199M/5.00G [00:00<00:18, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 231M/5.00G [00:00<00:18, 262MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 262M/5.00G [00:01<00:18, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 294M/5.00G [00:01<00:18, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 336M/5.00G [00:01<00:16, 277MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 367M/5.00G [00:01<00:17, 269MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 398M/5.00G [00:01<00:17, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 430M/5.00G [00:01<00:17, 267MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 461M/5.00G [00:01<00:17, 253MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 493M/5.00G [00:01<00:18, 248MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 524M/5.00G [00:03<01:00, 74.4MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 577M/5.00G [00:03<00:38, 115MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 619M/5.00G [00:03<00:29, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 650M/5.00G [00:03<00:26, 165MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 682M/5.00G [00:03<00:23, 186MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 724M/5.00G [00:03<00:19, 219MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 755M/5.00G [00:03<00:18, 233MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 797M/5.00G [00:03<00:16, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 828M/5.00G [00:03<00:16, 258MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 870M/5.00G [00:04<00:14, 283MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 912M/5.00G [00:04<00:13, 295MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 965M/5.00G [00:04<00:12, 330MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 1.01G/5.00G [00:04<00:13, 305MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.05G/5.00G [00:04<00:14, 278MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.08G/5.00G [00:04<00:13, 283MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.12G/5.00G [00:04<00:13, 292MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.15G/5.00G [00:05<00:13, 284MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.18G/5.00G [00:05<00:15, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.23G/5.00G [00:05<00:13, 275MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.26G/5.00G [00:05<00:13, 272MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.29G/5.00G [00:05<00:14, 248MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.33G/5.00G [00:05<00:13, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.36G/5.00G [00:05<00:14, 255MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.39G/5.00G [00:06<00:14, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.43G/5.00G [00:06<00:16, 211MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.46G/5.00G [00:06<00:15, 232MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.50G/5.00G [00:06<00:13, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.54G/5.00G [00:06<00:12, 275MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.57G/5.00G [00:06<00:12, 267MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.60G/5.00G [00:06<00:13, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.64G/5.00G [00:07<00:19, 168MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.68G/5.00G [00:07<00:24, 138MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.71G/5.00G [00:07<00:21, 157MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.74G/5.00G [00:07<00:18, 179MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.78G/5.00G [00:07<00:14, 215MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.82G/5.00G [00:08<00:13, 239MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.86G/5.00G [00:08<00:13, 241MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.90G/5.00G [00:08<00:11, 265MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.94G/5.00G [00:08<00:11, 277MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.97G/5.00G [00:08<00:11, 274MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 2.00G/5.00G [00:08<00:10, 281MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 2.04G/5.00G [00:08<00:09, 299MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.09G/5.00G [00:08<00:09, 314MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.13G/5.00G [00:09<00:09, 311MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.16G/5.00G [00:09<00:13, 204MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.20G/5.00G [00:09<00:11, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.24G/5.00G [00:09<00:10, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.28G/5.00G [00:09<00:10, 271MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.32G/5.00G [00:09<00:08, 302MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.36G/5.00G [00:09<00:08, 300MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.40G/5.00G [00:10<00:08, 305MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.44G/5.00G [00:10<00:09, 282MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.47G/5.00G [00:10<00:09, 280MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.51G/5.00G [00:10<00:09, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.54G/5.00G [00:10<00:09, 270MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.57G/5.00G [00:10<00:09, 261MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.60G/5.00G [00:10<00:09, 241MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.63G/5.00G [00:11<00:10, 235MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.67G/5.00G [00:11<00:09, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.71G/5.00G [00:11<00:09, 234MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.74G/5.00G [00:11<00:09, 228MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.78G/5.00G [00:11<00:08, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.81G/5.00G [00:11<00:08, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.84G/5.00G [00:11<00:08, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.87G/5.00G [00:12<00:08, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.90G/5.00G [00:12<00:08, 254MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.95G/5.00G [00:12<00:07, 270MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 2.98G/5.00G [00:12<00:07, 256MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 3.01G/5.00G [00:12<00:08, 242MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.04G/5.00G [00:12<00:07, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:12<00:08, 240MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.10G/5.00G [00:13<00:09, 199MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.14G/5.00G [00:13<00:08, 208MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.17G/5.00G [00:13<00:08, 225MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.21G/5.00G [00:13<00:07, 238MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.24G/5.00G [00:13<00:07, 228MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.27G/5.00G [00:13<00:07, 228MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.30G/5.00G [00:13<00:07, 233MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.33G/5.00G [00:14<00:07, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.37G/5.00G [00:14<00:06, 245MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.40G/5.00G [00:14<00:06, 254MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.43G/5.00G [00:14<00:06, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.46G/5.00G [00:14<00:05, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.49G/5.00G [00:14<00:05, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.52G/5.00G [00:14<00:05, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.55G/5.00G [00:14<00:05, 261MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.59G/5.00G [00:14<00:05, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.62G/5.00G [00:15<00:05, 258MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.65G/5.00G [00:15<00:05, 262MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.68G/5.00G [00:15<00:05, 263MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.71G/5.00G [00:15<00:04, 264MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.74G/5.00G [00:15<00:04, 265MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.77G/5.00G [00:15<00:04, 268MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.81G/5.00G [00:15<00:04, 269MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.84G/5.00G [00:15<00:04, 254MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.87G/5.00G [00:16<00:04, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.90G/5.00G [00:16<00:04, 226MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.93G/5.00G [00:16<00:04, 220MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.96G/5.00G [00:16<00:04, 223MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80% 4.00G/5.00G [00:16<00:04, 220MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.03G/5.00G [00:16<00:04, 214MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.06G/5.00G [00:16<00:04, 218MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.09G/5.00G [00:17<00:04, 205MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.11G/5.00G [00:17<00:04, 193MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.13G/5.00G [00:17<00:04, 192MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.16G/5.00G [00:17<00:04, 206MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.19G/5.00G [00:17<00:03, 223MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.24G/5.00G [00:17<00:02, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.28G/5.00G [00:17<00:02, 272MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.31G/5.00G [00:18<00:02, 256MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.35G/5.00G [00:18<00:02, 271MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.38G/5.00G [00:18<00:02, 246MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.41G/5.00G [00:18<00:02, 242MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.45G/5.00G [00:18<00:02, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.48G/5.00G [00:18<00:02, 252MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.51G/5.00G [00:18<00:01, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.54G/5.00G [00:18<00:01, 246MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:19<00:01, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.61G/5.00G [00:19<00:01, 277MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.66G/5.00G [00:19<00:01, 288MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.70G/5.00G [00:19<00:00, 303MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.74G/5.00G [00:19<00:00, 327MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.78G/5.00G [00:19<00:00, 308MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.81G/5.00G [00:19<00:00, 291MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.85G/5.00G [00:19<00:00, 303MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.89G/5.00G [00:20<00:00, 306MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99% 4.93G/5.00G [00:20<00:00, 309MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:20<00:00, 244MB/s]\n",
            "Downloading shards:  50% 2/4 [00:44<00:44, 22.10s/it]\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 41.9M/4.92G [00:00<00:14, 348MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 83.9M/4.92G [00:00<00:18, 255MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 115M/4.92G [00:00<00:17, 273MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 147M/4.92G [00:00<00:17, 280MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 189M/4.92G [00:00<00:15, 302MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 220M/4.92G [00:00<00:15, 303MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 262M/4.92G [00:00<00:14, 315MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 304M/4.92G [00:00<00:14, 328MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 346M/4.92G [00:01<00:14, 310MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 377M/4.92G [00:01<00:22, 204MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 409M/4.92G [00:01<00:21, 213MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 461M/4.92G [00:01<00:16, 269MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 493M/4.92G [00:01<00:17, 253MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 524M/4.92G [00:07<03:26, 21.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 556M/4.92G [00:07<02:33, 28.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 587M/4.92G [00:07<01:54, 37.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 619M/4.92G [00:07<01:25, 50.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 650M/4.92G [00:07<01:04, 66.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 682M/4.92G [00:07<00:49, 85.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 724M/4.92G [00:07<00:36, 116MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 755M/4.92G [00:07<00:29, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 797M/4.92G [00:08<00:23, 175MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 839M/4.92G [00:08<00:18, 216MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 891M/4.92G [00:08<00:14, 270MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 933M/4.92G [00:08<00:19, 201MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 965M/4.92G [00:08<00:19, 201MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 996M/4.92G [00:08<00:18, 215MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 1.03G/4.92G [00:09<00:19, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.06G/4.92G [00:13<02:31, 25.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.10G/4.92G [00:13<01:41, 37.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.13G/4.92G [00:13<01:17, 48.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.16G/4.92G [00:13<00:59, 62.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.20G/4.92G [00:13<00:46, 79.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.23G/4.92G [00:13<00:37, 97.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.26G/4.92G [00:13<00:30, 120MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.29G/4.92G [00:14<00:28, 126MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.32G/4.92G [00:14<00:33, 108MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.34G/4.92G [00:19<03:32, 16.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.37G/4.92G [00:19<02:27, 24.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.42G/4.92G [00:19<01:34, 37.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.45G/4.92G [00:19<01:12, 48.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.48G/4.92G [00:19<00:55, 62.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.52G/4.92G [00:20<00:38, 88.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.55G/4.92G [00:20<00:31, 108MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.59G/4.92G [00:20<00:23, 142MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.63G/4.92G [00:20<00:20, 158MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.66G/4.92G [00:20<00:19, 169MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.69G/4.92G [00:20<00:17, 188MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.73G/4.92G [00:20<00:14, 223MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.76G/4.92G [00:21<00:15, 210MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.79G/4.92G [00:21<00:15, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.82G/4.92G [00:21<00:15, 203MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.86G/4.92G [00:21<00:14, 212MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.89G/4.92G [00:21<00:15, 199MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.92G/4.92G [00:25<01:53, 26.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.94G/4.92G [00:25<01:36, 30.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.98G/4.92G [00:25<01:02, 46.7MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 2.01G/4.92G [00:25<00:47, 60.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.04G/4.92G [00:26<00:36, 78.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.08G/4.92G [00:26<00:28, 100MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 2.12G/4.92G [00:26<00:20, 134MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.15G/4.92G [00:26<00:17, 159MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.18G/4.92G [00:26<00:15, 182MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.21G/4.92G [00:26<00:16, 168MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.25G/4.92G [00:26<00:12, 207MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.29G/4.92G [00:26<00:12, 210MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.32G/4.92G [00:27<00:11, 230MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.35G/4.92G [00:27<00:10, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.38G/4.92G [00:27<00:16, 158MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.41G/4.92G [00:28<00:44, 56.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.43G/4.92G [00:29<00:39, 62.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 2.47G/4.92G [00:29<00:26, 91.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.51G/4.92G [00:29<00:25, 94.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.56G/4.92G [00:29<00:17, 138MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.59G/4.92G [00:29<00:14, 161MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.62G/4.92G [00:29<00:12, 184MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.65G/4.92G [00:30<00:11, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.69G/4.92G [00:30<00:09, 240MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.73G/4.92G [00:30<00:08, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.76G/4.92G [00:30<00:09, 234MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.79G/4.92G [00:30<00:08, 249MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.82G/4.92G [00:30<00:09, 232MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.85G/4.92G [00:30<00:08, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.89G/4.92G [00:30<00:07, 262MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.93G/4.92G [00:31<00:07, 260MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.96G/4.92G [00:31<00:07, 264MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.99G/4.92G [00:31<00:07, 251MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 3.02G/4.92G [00:31<00:07, 259MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.05G/4.92G [00:31<00:09, 196MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.08G/4.92G [00:31<00:09, 193MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.11G/4.92G [00:32<00:11, 151MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 3.14G/4.92G [00:35<01:12, 24.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.18G/4.92G [00:35<00:45, 38.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.22G/4.92G [00:35<00:30, 56.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 3.25G/4.92G [00:35<00:23, 71.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.28G/4.92G [00:36<00:19, 84.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.31G/4.92G [00:36<00:15, 105MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.34G/4.92G [00:36<00:12, 125MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 3.38G/4.92G [00:36<00:10, 150MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.42G/4.92G [00:36<00:08, 185MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.46G/4.92G [00:36<00:06, 216MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.49G/4.92G [00:36<00:06, 211MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.52G/4.92G [00:37<00:06, 213MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.55G/4.92G [00:37<00:06, 225MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.59G/4.92G [00:37<00:07, 167MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.61G/4.92G [00:43<01:30, 14.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.64G/4.92G [00:43<01:02, 20.5MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.67G/4.92G [00:44<00:43, 28.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.71G/4.92G [00:44<00:27, 43.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.74G/4.92G [00:44<00:20, 57.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.77G/4.92G [00:44<00:15, 74.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.82G/4.92G [00:44<00:10, 104MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.85G/4.92G [00:44<00:08, 126MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.88G/4.92G [00:44<00:07, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.91G/4.92G [00:44<00:06, 166MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.94G/4.92G [00:45<00:06, 152MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.97G/4.92G [00:45<00:06, 148MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 4.01G/4.92G [00:45<00:05, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.04G/4.92G [00:45<00:04, 196MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.08G/4.92G [00:45<00:03, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.11G/4.92G [00:47<00:12, 66.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.14G/4.92G [00:47<00:11, 69.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.16G/4.92G [00:47<00:09, 80.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.18G/4.92G [00:47<00:07, 92.8MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.22G/4.92G [00:47<00:06, 116MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.25G/4.92G [00:47<00:04, 146MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.29G/4.92G [00:47<00:03, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 4.32G/4.92G [00:48<00:02, 202MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.35G/4.92G [00:48<00:02, 190MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.38G/4.92G [00:48<00:02, 178MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.41G/4.92G [00:48<00:02, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.45G/4.92G [00:48<00:02, 198MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:48<00:01, 233MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.52G/4.92G [00:49<00:01, 203MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.55G/4.92G [00:49<00:01, 209MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.58G/4.92G [00:49<00:01, 209MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.61G/4.92G [00:49<00:01, 157MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.63G/4.92G [00:50<00:04, 70.2MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 4.66G/4.92G [00:54<00:12, 20.3MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.71G/4.92G [00:54<00:05, 36.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.74G/4.92G [00:54<00:03, 47.6MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 4.77G/4.92G [00:54<00:02, 58.1MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.80G/4.92G [00:54<00:01, 76.0MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.84G/4.92G [00:54<00:00, 105MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.89G/4.92G [00:54<00:00, 135MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:55<00:00, 89.3MB/s]\n",
            "Downloading shards:  75% 3/4 [01:40<00:37, 37.27s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3% 31.5M/1.17G [00:00<00:04, 263MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   6% 73.4M/1.17G [00:00<00:07, 156MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  10% 115M/1.17G [00:00<00:04, 213MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 157M/1.17G [00:00<00:04, 232MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  16% 189M/1.17G [00:06<01:01, 15.9MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  19% 220M/1.17G [00:07<00:42, 22.2MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21% 241M/1.17G [00:07<00:33, 27.4MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24% 283M/1.17G [00:07<00:20, 42.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27% 315M/1.17G [00:07<00:15, 54.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  30% 346M/1.17G [00:07<00:11, 70.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 377M/1.17G [00:07<00:08, 88.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35% 409M/1.17G [00:07<00:06, 113MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  38% 440M/1.17G [00:08<00:05, 129MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  40% 472M/1.17G [00:08<00:04, 156MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  43% 503M/1.17G [00:08<00:03, 178MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46% 535M/1.17G [00:08<00:03, 184MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  49% 577M/1.17G [00:08<00:02, 224MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  52% 608M/1.17G [00:08<00:02, 223MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  55% 640M/1.17G [00:08<00:02, 208MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57% 671M/1.17G [00:08<00:02, 224MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  60% 703M/1.17G [00:09<00:02, 191MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  63% 734M/1.17G [00:10<00:06, 62.0MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  65% 755M/1.17G [00:10<00:06, 63.7MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  69% 807M/1.17G [00:10<00:03, 102MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 849M/1.17G [00:11<00:02, 133MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75% 881M/1.17G [00:11<00:01, 154MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78% 912M/1.17G [00:11<00:01, 179MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82% 954M/1.17G [00:11<00:00, 218MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  84% 986M/1.17G [00:11<00:00, 215MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  87% 1.02G/1.17G [00:11<00:00, 197MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  90% 1.05G/1.17G [00:12<00:01, 116MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92% 1.07G/1.17G [00:17<00:05, 17.6MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95% 1.11G/1.17G [00:17<00:02, 27.3MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:17<00:00, 66.5MB/s]\n",
            "Downloading shards: 100% 4/4 [01:57<00:00, 29.47s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:02<00:00,  1.71it/s]\n",
            "generation_config.json: 100% 234/234 [00:00<00:00, 1.40MB/s]\n",
            "[2024-10-10 09:25:56,645] [INFO] [axolotl.load_model:922] [PID:3385] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
            "[2024-10-10 09:25:58,490] [INFO] [axolotl.load_lora:1087] [PID:3385] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n",
            "[2024-10-10 09:25:59,137] [INFO] [axolotl.load_model:970] [PID:3385] [RANK:0] GPU memory usage after adapters: 0.000GB ()\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 72, in <module>\n",
            "    fire.Fire(do_cli)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 39, in do_cli\n",
            "    return do_train(parsed_cfg, parsed_cli_args)\n",
            "  File \"/content/axolotl/src/axolotl/cli/train.py\", line 67, in do_train\n",
            "    return train(cfg=cfg, cli_args=cli_args, dataset_meta=dataset_meta)\n",
            "  File \"/content/axolotl/src/axolotl/train.py\", line 124, in train\n",
            "    trainer = setup_trainer(\n",
            "  File \"/content/axolotl/src/axolotl/utils/trainer.py\", line 498, in setup_trainer\n",
            "    return trainer_builder.build(total_num_steps)\n",
            "  File \"/content/axolotl/src/axolotl/core/trainer_builder.py\", line 1625, in build\n",
            "    trainer = trainer_cls(\n",
            "  File \"/content/axolotl/src/axolotl/core/trainer_builder.py\", line 409, in __init__\n",
            "    super().__init__(*_args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 554, in __init__\n",
            "    self._move_model_to_device(model, args.device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 802, in _move_model_to_device\n",
            "    model = model.to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1174, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
            "    return t.to(\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 475.06 MiB is free. Process 35113 has 14.28 GiB memory in use. Of the allocated memory 14.06 GiB is allocated by PyTorch, and 129.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1174, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 769, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.train', '/content/drive/MyDrive/LLMTraining/LLama8Btraining/lora_config.yaml']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch -m axolotl.cli.train /content/drive/MyDrive/LLMTraining/LLama8Btraining/lora_config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYLltIF3tHSi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeGtSBtVsrIq",
        "outputId": "39876eeb-80c4-4acd-c154-8397818fc4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 10 09:13:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB7V7EHetJT0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ik3n_fK8RIBiU4p9mGp9bxeW0I9uikO-",
      "authorship_tag": "ABX9TyM4B4xPEGtf9G6ozxIVfEqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}