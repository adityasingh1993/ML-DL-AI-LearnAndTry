{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Bigram.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/adityasingh1993/100DayMLChallenge/blob/master/NLP_Bigram.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YEfET-W0n5OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fd5fbca9-40d0-4eff-898b-d78554484164"
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-24 15:12:45--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2018-10-24 15:12:45--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  2.52MB/s    in 9m 44s  \n",
            "\n",
            "2018-10-24 15:22:29 (3.06 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rXFFnwKonaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "01e4cd3c-208a-4652-b898-13c5f251b530"
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.42B.300d.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XSFCgpTStqI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "from future.utils import iteritems\n",
        "from builtins import range\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import pairwise_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqSxuXVysALt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88196f6e-2632-45d3-cbf5-5e64fd392747"
      },
      "cell_type": "code",
      "source": [
        "print(\"Loading Word Vector\")\n",
        "word2vec={}\n",
        "idx2word=[]\n",
        "embedding=[]\n",
        "\n",
        "with open('glove.42B.300d.txt') as f:\n",
        "  for line in f:\n",
        "    values=line.split()\n",
        "    word=values[0]\n",
        "    vec=np.asarray(values[1:],dtype='float32')\n",
        "    word2vec[word]=vec\n",
        "    embedding.append(vec)\n",
        "    idx2word.append(word)\n",
        "    \n",
        "  print(\"found {} number of words\".format(len(word2vec)))\n",
        "  embedding=np.asarray(embedding)\n",
        "  V,D=embedding.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Word Vector\n",
            "found 1917494 number of words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCyyFgunTvE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "97d0c244-6a13-4f36-c59d-d9cee11abf04"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "aLZMjLeLtoLX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "import operator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlkEmib5ilyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keep_word=set(['king','man','queen','woman','india','england'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FJbH-W0tQ5vG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getSentences():\n",
        "  return brown.sents()\n",
        "\n",
        "def getSentence_Word2idx():\n",
        "  i=2\n",
        "  sentences=getSentences()\n",
        "  indexed_sentences=[]\n",
        "  word2idx_brown={'START':0,'END':1}\n",
        "  for sentence in sentences:\n",
        "    indexed_sentence=[]\n",
        "    for token in sentence:\n",
        "      token=token.lower()\n",
        "      if token not in word2idx_brown:\n",
        "        word2idx_brown[token]=i\n",
        "        i+=1\n",
        "      indexed_sentence.append(word2idx_brown[token])\n",
        "    indexed_sentences.append(indexed_sentence)\n",
        "  \n",
        "  print(\"{} is th size of vocab\".format(i))\n",
        "  print(len(word2idx_brown))\n",
        "  \n",
        "  return indexed_sentences,word2idx_brown\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "plfNlUqPRQe5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getSentence_Word2idx_liitVocab(n_vocabs=2000,keep_word=keep_word):\n",
        "  i=2\n",
        "  sentences=getSentences()\n",
        "  indexed_sentences=[]\n",
        "  word2idx_brown={'START':0,'END':1}\n",
        "  idx2word_brown=['START','END']\n",
        "  \n",
        "  word_idx_count={\n",
        "      0:float('inf'),\n",
        "      1:float('inf')\n",
        "  }\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    indexed_sentence=[]\n",
        "    for token in sentence:\n",
        "      token=token.lower()\n",
        "      if token not in word2idx_brown:\n",
        "        idx2word_brown.append(token)\n",
        "        word2idx_brown[token]=i\n",
        "        i+=1\n",
        "        indexed_sentence.append(word2idx_brown[token])\n",
        "      idx=word2idx_brown[token]\n",
        "      word_idx_count[idx]=word_idx_count.get(idx,0)+1\n",
        "    indexed_sentences.append(indexed_sentence)\n",
        "      \n",
        "      \n",
        "      \n",
        "  for word in keep_word:\n",
        "    word_idx_count[word2idx_brown[word]]=float('inf')\n",
        "    \n",
        "  sorted_word_idx_count=sorted(word_idx_count.items(),key=operator.itemgetter(1),reverse=True)\n",
        "  word2idx_small={}\n",
        "  word2idx_small={'START':0,'END':1}\n",
        "  new_idx=0\n",
        "  idx_new_idx_map={}\n",
        "  \n",
        "  for idx,count in sorted_word_idx_count:\n",
        "    word=idx2word_brown[idx]\n",
        "    word2idx_small[word]=idx\n",
        "    idx_new_idx_map[idx]=new_idx\n",
        "    new_idx+=1\n",
        "    \n",
        " \n",
        "  word2idx_small['UNKNOWN']=new_idx\n",
        "  unknown=new_idx\n",
        "  \n",
        "  assert('START' in word2idx_small)\n",
        "  assert('END' in word2idx_small)\n",
        "  assert('UNKNOWN' in word2idx_small)\n",
        "  sentence_small=[]\n",
        "  for sentence in indexed_sentences:\n",
        "    if len(sentence)>1:\n",
        "      new_sentence=[idx_new_idx_map[idx] if idx in idx_new_idx_map else unknown for idx in sentence ]\n",
        "      sentence_small.append(new_sentence)\n",
        "      \n",
        "      \n",
        "  return sentence_small,word2idx_small,idx_new_idx_map\n",
        "      \n",
        "      \n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AwHR0-qTYJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bigram_probs(sentences,V,start_idx,end_idx,smoothing=1):\n",
        "  bigram_probs=np.ones((V,V))*smoothing\n",
        "  for sentence in sentences:\n",
        "     for i in range(len(sentence)):\n",
        "        if i==0:\n",
        "          bigram_probs[start_idx,sentence[i]]+=1\n",
        "        else:\n",
        "          bigram_probs[sentence[i-1],sentence[i]]+=1\n",
        "          \n",
        "        if i==len(sentence)-1:\n",
        "          bigram_probs[sentence[i-1],end_edx]+=1\n",
        "    \n",
        "  bigram_probs /= bigram_probs.sum(axis=1, keepdims=True)\n",
        "          \n",
        "  return bigram_probs\n",
        "          \n",
        "        \n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDwnB2vojHWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_Score(sentences,start_idx,end_idx):\n",
        "  score=0\n",
        "  for sentence in sentences:\n",
        "    for i in range(len(ssentence)):\n",
        "      if i==0:\n",
        "        score +=np.log(bigram_probs[start_idx,sentence[i]])\n",
        "      else:\n",
        "         score += np.log(bigram_probs[sentence[i-1],sentence[i]])\n",
        "        \n",
        "      if i==len(sentence)-1:\n",
        "          score += np.log(bigram_probs[sentence[i-1],end_edx])\n",
        "          \n",
        "    return score/len(sentence)+1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "whzS7tJynb0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  sentence_small,word2idx_small,idx2word_small=getSentence_Word2idx_liitVocab(1000)\n",
        "  V=len(word2idx_small)\n",
        "  print(len(word2idx_small))\n",
        "  start_idx=word2idx_small['START']\n",
        "  end_idx=word2idx_small['END']\n",
        "  bigram_probs=get_bigram_probs(sentence_small,V,start_idx,end_idx,smoothing=1)\n",
        "  return bigram_probs,word2idx_small"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VienaKOFobNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fde970b3-1b2d-4564-de1c-b40aa375f3bc"
      },
      "cell_type": "code",
      "source": [
        "bigram_probs,word2idx_small=main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5VpX7YMoctc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx2word_small=dict((k,v) for k,v in iteritems(word2idx_small))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xJP_xtZtxVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_words(sentence):\n",
        "  return ' '.join( idx2word_small[i] in sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cnCb0HbuVcj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_prob=np.ones((V))\n",
        "sample_prob[start_idx]=0\n",
        "sample_prob[end_idx]=0\n",
        "sample_prob /= sample_prob.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvxPFxjFuqAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  real_idx=np.random.choice(len(sentences))\n",
        "  real=sentences[real_idx]\n",
        "  fake=np.random.choices(V,size=len(real),p=sample_prob)\n",
        "  print(\"Real is {0} and Score is {1}\".format(get_words(real),get_score(real)))\n",
        "  print(\"Fake is {0} and Score is {1}\".format(get_words(real),get_score(real)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}